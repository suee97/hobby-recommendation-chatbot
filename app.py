# ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜ í•„ìš”
# pip install fastapi uvicorn openai python-dotenv

# ì´ì œ pip install -r requirements.txtë¡œ ê°„ë‹¨í•˜ê²Œ ì„¤ì¹˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
# ê°€ìƒí™˜ê²½ ì„¤ì •ì´ í•„ìš”í•˜ë‹¤ë©´ notionì˜ python ê°€ìƒí™˜ê²½ ì„¤ì •ì„ ì°¸ê³ í•´ì£¼ì„¸ìš”.
# ì¶”ê°€: .env íŒŒì¼ì— SOLAR_LLM_API_KEY = 'ë°›ì€ API KEY' ì¶”ê°€í•´ì£¼ì„¸ìš”.

from fastapi import FastAPI
import json
from fastapi.middleware.cors import CORSMiddleware
from dotenv import load_dotenv
from openai import OpenAI
from pydantic import BaseModel
import os, random, string
from datetime import datetime, timedelta
from recommend_hobby import Hobby_recommender

# ìƒˆë¡œ ì¶”ê°€ëœ ëª¨ë“ˆ import
from hobby_service import HobbyRecommendationService
from util.llm_tools import llm_functions

app = FastAPI() 

# API KEY ë¶ˆëŸ¬ì˜¤ê¸°
load_dotenv()
SOLAR_LLM_API_KEY = os.getenv('SOLAR_LLM_API_KEY')

# Solar LLM
client = OpenAI(
    api_key=SOLAR_LLM_API_KEY,
    base_url="https://api.upstage.ai/v1"
)

# ì·¨ë¯¸ ì¶”ì²œ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
hobby_service = HobbyRecommendationService()

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# 'python app.py' ì‹¤í–‰ì‹œ ì„œë²„ ì—´ë„ë¡ í•˜ëŠ” ì½”ë“œ
if __name__ == "__main__":
    import uvicorn
    uvicorn.run("app:app", host="0.0.0.0", port=8000, reload=True)

# ì„¸ì…˜ ê´€ë¦¬ - ê¸°ì¡´ êµ¬ì¡° ìœ ì§€í•˜ë˜ ì·¨ë¯¸ ì¶”ì²œ ë°ì´í„° ì¶”ê°€
chat_storage = {
    'test-token': [[], datetime(2099, 1, 1, 0, 0)],
    'old-token': [[], datetime(2025, 6, 1, 12, 0)],
}

# Model
class ChatRequestModel(BaseModel):
    token: str
    message: str

class HobbyRecommenderModel(BaseModel):
    token : str
    user_desc : str
    user_hobby : str


# API
@app.get("/generate-token")
def generate_token():
    characters = string.ascii_letters + string.digits
    token = ''.join(random.choice(characters) for _ in range(20))
    if token not in chat_storage:
        # ê¸°ì¡´ êµ¬ì¡°ì— ì·¨ë¯¸ ì¶”ì²œ ë°ì´í„° ì¶”ê°€
        session_data = hobby_service.create_session_data()
        session_data[1] = datetime.now()  # timestamp ì„¤ì •
        chat_storage[token] = session_data
    return {"statusCode": 200, "data": {"token": token}}

@app.post("/chat")
def chat_post(req: ChatRequestModel):
    # í† í° ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸, ì—†ìœ¼ë©´ ì—ëŸ¬
    if req.token not in chat_storage:
        return {"statusCode": 400, "errorMessage": "ì„œë²„ì— ì¡´ì¬í•˜ì§€ ì•ŠëŠ” í† í°ì…ë‹ˆë‹¤."}
    
    # ì„¸ì…˜ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    session_data = chat_storage[req.token]
    history = session_data[0]
    
    # ì²« ëŒ€í™”ì¼ ë•Œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì¶”ê°€
    if len(history) == 0:
        history.append({"role": "system", "content": hobby_service.get_system_prompt()})
    
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    newChat = {"role": "user", "content": req.message}
    history.append(newChat)

    # Solar LLMì— ìš”ì²­ ë³´ë‚´ê³  ì‘ë‹µ ë°›ê¸°
    response_format = {
        "type": "json_schema",
        "json_schema": {
            "name": "tendency_chat",
            "strict": True,
            "schema": {
                "type": "object",
                "properties": {
                    "message": {
                        "type": "string",
                        "description": "assistant chat response"
                    },
                    "summary": {
                        "type": "string",
                        "description": "user tendency summary. (if completed)"
                    },
                    "recommended_hobby": {
                        "type": "string",
                        "description": "user tendency summary. (if completed)"
                    },
                    "question_count": {
                        "type": "number",
                        "description": "number of question"
                    },
                    "is_completed": {
                        "type": "boolean",
                        "description": "if completly grasp user tendency, then true else false"
                    }
                },
                "required": ["message", "summary", "recommended_hobby", "question_count", "is_completed"]
            }
        }
    }

    stream = client.chat.completions.create(
        model = "solar-mini",
        messages = history,
        response_format = response_format,
        stream = True,
    )
    answer = ''
    for chunk in stream:
        if chunk.choices[0].delta.content is not None:
            answer += chunk.choices[0].delta.content
    print(answer)
    # arguments_str = response.choices[0].message.function_call.arguments
    # result = json.loads(arguments_str)
    
    # =================== [ AI ë‹µë³€ í™•ì¸ ì½”ë“œ ] ===================
    # print("\n" + "="*60)
    # print("ğŸ¤– AIì˜ ì›ë³¸ ë‹µë³€:", answer)
    # print("="*60 + "\n")
    # ==========================================================


    # AI ì‘ë‹µì„ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
    history.append({"role": "assistant", "content": answer})

    return {"d":"dd"}
    ####################################################

    # AI ì‘ë‹µ íŒŒì‹± ë° ì„¸ì…˜ ë°ì´í„° ì—…ë°ì´íŠ¸
    response_data, summary, recommended_hobby = hobby_service.parse_ai_response(answer)
    
    if response_data:
        # ì‚¬ìš©ì ë°ì´í„° ì—…ë°ì´íŠ¸
        if "user_data" in response_data:
            session_data[2].update(response_data["user_data"])
        # ì§ˆë¬¸ ì¹´ìš´íŠ¸ ì—…ë°ì´íŠ¸
        if "question_count" in response_data:
            session_data[3] = response_data["question_count"]
        # ì™„ë£Œ ìƒíƒœ ì—…ë°ì´íŠ¸
        if "is_complete" in response_data:
            session_data[4] = response_data["is_complete"]
    else:
        # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì˜ˆì™¸ ì²˜ë¦¬ (ì˜ˆ: ì‚¬ìš©ìì—ê²Œ ì¬ì§ˆë¬¸ ìœ ë„)
        response_data = {"is_complete": False, "message": "ì£„ì†¡í•´ìš”, ë‹µë³€ì„ ì´í•´í•˜ì§€ ëª»í–ˆì–´ìš”. ë‹¤ì‹œ í•œë²ˆ ë§ì”€í•´ì£¼ì‹œê² ì–´ìš”?"}
        summary = ""
        recommended_hobby = ""
    
    # íƒ€ì„ìŠ¤íƒ¬í”„ ì—…ë°ì´íŠ¸
    session_data[1] = datetime.now()

    # ì„¸ì…˜ 30ë¶„ ë„˜ì€ ê°’ë“¤ ì§€ìš°ê¸° (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
    expire_delta = timedelta(minutes=30)
    keys_to_delete = []
    for token, data in chat_storage.items():
        if datetime.now() - data[1] > expire_delta:
            keys_to_delete.append(token)
    for token in keys_to_delete:
        del chat_storage[token]


    # ëŒ€í™” ì¢…ë£Œ ì „
    if response_data["is_complete"] is not None and not response_data["is_complete"]:
        return {"statusCode": 200, "data": {
            "response_data": response_data,
            "message": response_data["message"],
            "is_complete": response_data["is_complete"],
            "summary": summary,
            "recommended_hobby": recommended_hobby,
        }}
    
    # ëŒ€í™” ì¢…ë£Œ
    else:
        recommend_req = HobbyRecommenderModel(
            token=req.token,
            user_desc=summary,
            user_hobby="none"
        )
        result = recommend_post(recommend_req)
        return {"statusCode": 200, "data": {"recommend_result": result}}


    

@app.post("/recommend-hobby")
def recommend_post(req: HobbyRecommenderModel):
    # í† í° ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸, ì—†ìœ¼ë©´ ì—ëŸ¬
    # if req.token not in chat_storage:
    #     return {"statusCode": 400, "errorMessage": "ì„œë²„ì— ì¡´ì¬í•˜ì§€ ì•ŠëŠ” í† í°ì…ë‹ˆë‹¤."}

    hobby_recommender = Hobby_recommender(os.getenv("SERPAPI_API_KEY"))
    result = hobby_recommender.recommend(req.user_desc, req.user_hobby)


    return result
    # ì‘ë‹µ ë°ì´í„° êµ¬ì„±
    response = {
        "answer": answer,
        "user_data": session_data[2],
        "question_count": session_data[3],
        "is_profiling_done": session_data[4]
    }
    
    # ì™„ë£Œëœ ê²½ìš° ì¶”ê°€ ì •ë³´ í¬í•¨
    if summary:
        response["summary"] = summary
    if recommended_hobby:
        response["recommended_hobby"] = recommended_hobby

    return {"statusCode": 200, "data": response}

# ì¶”ê°€ API: ì‚¬ìš©ì ë°ì´í„° ì¡°íšŒ
@app.get("/user-data/{token}")
def get_user_data(token: str):
    """ì‚¬ìš©ì ë°ì´í„° ì¡°íšŒ API"""
    if token not in chat_storage:
        return {"statusCode": 400, "errorMessage": "ì„œë²„ì— ì¡´ì¬í•˜ì§€ ì•ŠëŠ” í† í°ì…ë‹ˆë‹¤."}
    
    session_data = chat_storage[token]
    return {"statusCode": 200, "data": {
        "user_data": session_data[2],
        "question_count": session_data[3],
        "is_profiling_done": session_data[4]
    }}